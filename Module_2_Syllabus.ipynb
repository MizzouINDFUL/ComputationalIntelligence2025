{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textbook\n",
    "\n",
    "<img src=\"https://images-na.ssl-images-amazon.com/images/I/51x-ilFCcsL._SX313_BO1,204,203,200_.jpg\">\n",
    "\n",
    "https://onlinelibrary.wiley.com/doi/book/10.1002/9781119214403\n",
    "\n",
    "Title: Fundamentals of Computational Intelligence: Neural Networks, Fuzzy Systems, and Evolutionary Computation\n",
    "\n",
    "Authors: David B Fogel, Derong Liu, James M Keller (a MU professor!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syllabus\n",
    "\n",
    "### Grading Scale\n",
    "\n",
    "Assigned on a linguistic (you will understand this after the fuzzy section!) \"A+\", \"A\", \"A-\", \"B+\", etc.\n",
    "\n",
    "### Exams, Projects, and Participation\n",
    "\n",
    "* 5% participation (e.g., class attendance)\n",
    "* 5% homework\n",
    "* 30% in class exams (aka have to know the theory)\n",
    "  * Exam 1: 10%\n",
    "  * Exam 2: 10%\n",
    "  * Exam 3: 10%\n",
    "* 60% projects (aka need to be able to apply these concepts)\n",
    "  * EC project: 20%\n",
    "  * FS project: 20%\n",
    "  * NN project: 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Withdrawal/Incomplete/Medical Situations\n",
    "\n",
    "Over the period of a semester there is the possibility of a medical situation, family emergency, or other problem that might impair your ability to participate successfully in this class. If this situation occurs, it is the student's responsibility to communicate with the instructor. If you have any emergency that causes you to miss an assignment, please provide the instructor with written documentation ASAP.  Specific decisions will be made on a case-by-case basis on the discretion of the instructor regarding all grades and possible recommendations for an official withdrawal or incomplete standing for the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Late Work\n",
    "\n",
    "Do all homework assignments and turn in by due date. Your grade will be lowered one full letter grade for each 3 days that any assignment is late (ex. an \"A\" becomes a \"B.\"). An assignment is considered late if it is not turned in by the day and time that the assignment is due. If you are worried about turning in the day something is due, I encourage you to turn it in earlier if you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plagiarism\n",
    "\n",
    "DO NOT PLAGIARIZE. PLAGIARISM IS CONSIDERED ACADEMIC DISHONESTY AND IS SUBJECT TO SEVERE SANCTIONS, INCLUDING POSSIBLE DISMISSAL FROM CLASS OR DISMISSAL FROM THE UNIVERSITY."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GenAI Integration Policy\n",
    "\n",
    "I encourage the use of GenAI tools (e.g., ChatGPT) in this course, but with guidelines on how and when they are appropriate. Appropriate uses include:\n",
    "\n",
    "* Understanding course concepts\n",
    "  * You may ask GenAI to explain topics such as Computational Intelligence in different ways than the textbook or lectures, provide examples (conceptual or numeric), or engage in back-and-forth discussions to clarify your understanding or go deeper.\n",
    "    * Remember: GenAI is only one source of information. Its responses may contain errors or biases. Always verify the information and think critically.\n",
    "* Programming support\n",
    "  * This course assumes you can program, but programming (the code itself) itself is not graded. GenAI can be helpful whether you are new to coding or an expert (for automating tasks like data loaders, plotting, or debugging). However, you are fully responsible for the code you submit. If GenAI produces errors, you cannot excuse them by saying, “GenAI made a mistake.”\n",
    "\n",
    "* Restrictions on Use\n",
    "  * Exams:\n",
    "    * GenAI is not allowed during exams or any in-class pen-and-paper assessments. Relying on GenAI for day-to-day work instead of genuine learning will leave you unprepared for exams, which count for 30% of your grade.\n",
    "  * Projects:\n",
    "    * Allowed:\n",
    "      * Using GenAI to assist with coding (debugging, writing utility functions, improving efficiency).\n",
    "      * Using GenAI to help with report writing mechanics (formatting, organization, grammar).\n",
    "    * Not allowed:\n",
    "      * Using GenAI for algorithm design—you must develop the Computational Intelligence algorithms yourself.\n",
    "      * Using GenAI to generate report content such as descriptions of algorithms, explanations of what you did, summaries of results, or conclusions. These must be your own original work.\n",
    "\n",
    "* Key Principle\n",
    "  * GenAI should enhance and accelerate your learning by providing tailored explanations and collaborative support, but your work must ultimately reflect your own understanding and ideas. At any time, I may ask you to explain code or concepts you submitted. If you cannot explain something you will get a zero on that assignment.\n",
    "\n",
    "* Final Note\n",
    "  * If you are unsure whether your intended use of GenAI is acceptable, ask me. You will not be penalized for clarifying, but you may be penalized for crossing the line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tentative Schedule\n",
    "\n",
    "## Introduction\n",
    "\n",
    "#### Aug 22th: \n",
    "\n",
    " * Intro to CI and Jupyter\n",
    "\n",
    "## Evolutionary Algorithms\n",
    "\n",
    "#### Aug 26th: Introduction to Evolutionary Algorithms\n",
    "\n",
    " * Natural selection (https://en.wikipedia.org/wiki/Natural_selection and https://education.nationalgeographic.org/resource/natural-selection) and survival of the fittest (https://en.wikipedia.org/wiki/Survival_of_the_fittest) - which are not the same (https://www.jstor.org/stable/22572?seq=2#metadata_info_tab_contents)\n",
    " * Encoding techniques (Holland and schema theory, https://en.wikipedia.org/wiki/Holland%27s_schema_theorem)(misc. https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1223575, and https://ieeexplore.ieee.org/document/592265)\n",
    " * Fitness function - structure of a fitness function and benchmark functions (https://en.wikipedia.org/wiki/Test_functions_for_optimization)\n",
    " * Initilization techniques and termination\n",
    "\n",
    "#### Aug 28th: Genetic Algorithms Part I\n",
    "\n",
    " * Selection and reproduction (e.g., random, proportional, tournament, rank-based, elitism)\n",
    " * Crossover (e.g., (binary and n-point)(floating point and UNDX, SPX, PCX))\n",
    " * Mutation (e.g., (binary and random, inorder, Gaussian)(floating point))\n",
    " * Exploitation vs exploration - what are they and why do we need them?  \n",
    " * [First GA for ML](EvolutionaryComputation/GA.ipynb)\n",
    " * [First GA on Benchmark Function](EvolutionaryComputation/GA2.ipynb)\n",
    "\n",
    "#### Sept 2nd: Genetic Algorithms Part II\n",
    "\n",
    " * More advanced concepts\n",
    " * Constraint handling\n",
    " * Island EAs and co-evolution\n",
    "\n",
    "#### Sept 4th: Genetic Programming\n",
    "\n",
    " * What is a genetic program (GP)?\n",
    " * Applications/examples\n",
    " * Tailored fitness, crossover, and mutation operators\n",
    " \n",
    "#### Sept 9th: Particle Swarm Optimization\n",
    "\n",
    " * Basic PSO mathematics\n",
    " * [Global best PSO algorithm](EvolutionaryComputation/GBest.ipynb)\n",
    " * Local best PSO algorithm\n",
    " * Cognitive and social components\n",
    "\n",
    "#### Sept 11th: Particle Swarm Optimization Part II\n",
    "\n",
    " * Social network structures\n",
    " * Convergence\n",
    " * Implementation details : init, clamping, inertia, and constraints\n",
    "\n",
    "#### Sept 16th: Exam 1\n",
    "\n",
    "## Fuzzy Sets\n",
    "\n",
    "#### Sept 18th: Motivation and What is a Fuzzy Set?\n",
    "\n",
    " * Zadeh: https://www2.eecs.berkeley.edu/Faculty/Homepages/zadeh.html\n",
    " * Fuzzy Set: https://www.sciencedirect.com/science/article/pii/S001999586590241X\n",
    " * Ling Var Part 1: https://www.sciencedirect.com/science/article/pii/0020025575900468?via%3Dihub\n",
    " * Ling Var Part 2: https://www.sciencedirect.com/science/article/pii/0020025575900468?via%3Dihub\n",
    " * Ling Var Part 3: https://www.sciencedirect.com/science/article/pii/0020025575900171?via%3Dihub\n",
    " * [Fuzzy Set](FuzzySets/FuzzySet.ipynb)\n",
    "\n",
    "#### Sept 23rd: Fuzzy Set Theory Basics and Operators (T-norms, T-conorms, and Complement) \n",
    "\n",
    " * Useful resource: https://cours.etsmtl.ca/sys843/REFS/Books/ZimmermannFuzzySetTheory2001.pdf\n",
    " * [Operators](FuzzySets/Operators.ipynb)\n",
    " \n",
    "#### Sept 25th: Alpha Cuts, Decomposition Theorem, and the Extension Principle \n",
    "\n",
    " * Useful resource: https://cran.r-project.org/web/packages/FuzzyNumbers/vignettes/FuzzyNumbersTutorial.pdf\n",
    " * [Extension Principle](FuzzySets/ExtensionPrinciple.ipynb)\n",
    " * Our generalized extension principle, https://ieeexplore.ieee.org/document/9132631\n",
    "\n",
    "#### Sept 30th: Fuzzy Relationships and Introduction to Fuzzy Logic\n",
    "\n",
    " * JuzzyOnline, https://juzzy.azurewebsites.net\n",
    " * [Fuzzy Relation](FuzzySets/FuzzyRelation.ipynb)\n",
    "\n",
    "#### Oct 2nd: Fuzzy Logic and Compositional Rule of Inference\n",
    "\n",
    " * Modus Ponens: https://en.wikipedia.org/wiki/Modus_ponens\n",
    " * Modus Tollens: https://en.wikipedia.org/wiki/Modus_tollens\n",
    " * [Rule of Composition](FuzzySets/ROC.ipynb)\n",
    " \n",
    "#### Oct 7th: Fuzzy Logic and Compositional Rule of Inference Part II\n",
    "\n",
    "#### Oct 9th: Mamdani/Sugeno and Takagi/Sugeno/Kang Fuzzy Inference Systems\n",
    "\n",
    " * Mamdani and Sugeno Fuzzy Inference System\n",
    "   * https://www.mathworks.com/help/fuzzy/types-of-fuzzy-inference-systems.html\n",
    " * Takagi, Sugeno, Kang Fuzzy Inference System, example:\n",
    "   * http://derektanderson.com/pdfs/blake_wcci_2020.pdf\n",
    " * [Example Fuzzy Logic System](FuzzySets/FLS.ipynb)\n",
    "\n",
    "#### Oct 14th: Ordered Weighted Average and the Fuzzy Integral\n",
    " \n",
    " * [OWA](FuzzySets/OWA.ipynb)\n",
    " * [Fuzzy Measure](FuzzySets/FuzzyMeasure.ipynb)\n",
    " * [Sugeno Integral](FuzzySets/SugenoIntegral.ipynb)\n",
    " * [Choquet Integral](FuzzySets/ChoquetIntegral.ipynb)\n",
    " * [Sugeno Lambda FM](FuzzySets/SugenoLambdaFM.ipynb) \n",
    " * Papers on the fuzzy integral and data-driven learning, http://derektanderson.com/pubs.html \n",
    " \n",
    "#### Oct 16th: Aggregation Part II\n",
    "\n",
    "#### Oct 21st: Fuzzy C-Means Clustering \n",
    " \n",
    " * [Fuzzy C-Means](FuzzySets/FCM.ipynb)\n",
    "   * Bezdek: https://www.researchgate.net/publication/222868331_FCM-the_Fuzzy_C-Means_clustering-algorithm\n",
    "   \n",
    "#### Oct 23rd: Fuzzy C-Means Clustering Part II \n",
    "\n",
    " * [Fuzzy C-Means GK](FuzzySets/FCM_Mah.ipynb)\n",
    " * GK metric\n",
    "   * https://www.researchgate.net/publication/224681053_Fuzzy_Clustering_with_a_Fuzzy_Covariance_Matrix\n",
    " * [VAT](FuzzySets/vat_and_ivat_example.ipynb) example\n",
    " * External measures of cluster validity \n",
    "\n",
    "#### Oct 28th: Exam 2\n",
    "\n",
    "## Neural Networks\n",
    "\n",
    "#### Oct 30st: History, the McCulloch-Pitts Neuron, and the Perceptron\n",
    "\n",
    " * [History of NNs](NeuralNets/NNHistory.ipynb)\n",
    " * [McCulloch-Pitts Neuron in NumPy](NeuralNets/McCulloch-PittsNeuronInNumPy.ipynb)\n",
    " * [Hand Coded Perceptron in NumPy](NeuralNets/HandCodedPerceptronInNumPy.ipynb)\n",
    "  \n",
    "#### Nov 4th: Perceptron and Gradient Descent\n",
    "\n",
    " * Perceptron Learning Algorithm additional text http://hagan.okstate.edu/4_Perceptron.pdf \n",
    " * [Perceptron in PyTorch](NeuralNets/PerceptronPyTorch.ipynb)\n",
    " * [Linear Regression in PyTorch](NeuralNets/LinearRegressionInPyTorch.ipynb)\n",
    " \n",
    "#### Nov 6th: Multi-Layer Perceptron and BackPropagation\n",
    "\n",
    " * [MLP in Action](NeuralNets/SeeMlpInAction.ipynb) \n",
    " * [MLP in PyTorch](NeuralNets/MlpInPyTorch.ipynb)\n",
    " * [Backprop](NeuralNets/BackProp.ipynb)\n",
    " * [TensorBoard](NeuralNets/TensorBoard.ipynb)\n",
    "\n",
    "#### Nov 11th: BackPropagation Part II and (Mini)Batch Learning\n",
    "\n",
    " * [Vanilla BackProp in NumPy](NeuralNets/BackPropInNumPy.ipynb)\n",
    " * [Mini Batch](NeuralNets/MiniBatch.ipynb) and [Dataset utils](NeuralNets/dataset_utils.py)\n",
    "\n",
    "#### Nov 13th: Evaluation (Confusion Matrices and Cross-Validation) and Faster NNs via Linear Algebra \n",
    "\n",
    " * Confusion matrices: https://en.wikipedia.org/wiki/Confusion_matrix, \n",
    " * Useful activation functions: https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html\n",
    " * [Confusion Matrix Example in Python](NeuralNets/ConfMat.ipynb)\n",
    "\n",
    "#### Nov 18th: Momentum and Loss Functions\n",
    " \n",
    " * [Gradient Descent](NeuralNets/GD.ipynb)\n",
    " * [Loss](NeuralNets/Loss.ipynb)\n",
    " * Examples\n",
    "   * https://medium.com/@phuctrt/loss-functions-why-what-where-or-when-189815343d3f\n",
    "   * https://medium.com/udacity-pytorch-challengers/a-brief-overview-of-loss-functions-in-pytorch-c0ddb78068f7\n",
    "   * https://pytorch.org/docs/stable/nn.html \n",
    " \n",
    "#### Nov 20th: Shared Weight Neural Networks (SWNNs) and Convolution\n",
    "\n",
    " * Total derivative and chain rule\n",
    "   * https://en.wikipedia.org/wiki/Total_derivative\n",
    "   * https://tutorial.math.lamar.edu/classes/calciii/chainrule.aspx\n",
    "   * http://sites.science.oregonstate.edu/math/home/programs/undergrad/CalculusQuestStudyGuides/vcalc/chain/chain.html\n",
    "\n",
    "#### Nov 25th: Thanksgiving break\n",
    "\n",
    "#### Nov 28th: Thanksgiving break\n",
    "\n",
    "#### Dec 2nd: Autoencoders\n",
    "\n",
    " * [Autoencoder](NeuralNets/Autoencoder.ipynb) \n",
    "\n",
    "#### Dec 4th: TBD\n",
    "\n",
    "#### Dec 9th: Exam 3\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
